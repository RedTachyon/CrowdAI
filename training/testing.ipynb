{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from models import MLPModel, FancyMLPModel\n",
    "from agents import Agent\n",
    "from collectors import Memory, CrowdCollector\n",
    "from environments import UnityCrowdEnv, UnitySimpleCrowdEnv\n",
    "from policy_optimization import CrowdPPOptimizer\n",
    "from trainers import PPOCrowdTrainer\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "from utils import transpose_batch, concat_batches, concat_crowd_batch, tanh_norm, atanh_unnorm\n",
    "\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import discount_rewards_to_go, get_episode_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The communication API versions between Unity and python differ at the minor version level. Python API: 1.2.0, Unity API: 1.0.\n",
      "This means that some features may not work unless you upgrade the package with the lower version.Please find the versions that work best together from our release page.\n",
      "https://github.com/Unity-Technologies/ml-agents/releases\n"
     ]
    }
   ],
   "source": [
    "# channel = EngineConfigurationChannel()\n",
    "\n",
    "\n",
    "# env = UnityCrowdEnv(file_name=\"Test.app\", side_channels=[channel], no_graphics=False)\n",
    "# env = UnityCrowdEnv(file_name=None)\n",
    "env = UnitySimpleCrowdEnv(file_name=None)\n",
    "\n",
    "\n",
    "\n",
    "# channel.set_configuration_parameters(time_scale=1, width=1000, height=1000, quality_level=0)#, target_frame_rate=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.engine_channel.set_configuration_parameters(time_scale=100, width=1000, height=1000, quality_level=0)#, target_frame_rate=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel({\n",
    "    \"input_size\": 90,\n",
    "})\n",
    "\n",
    "# agent = Agent(model)\n",
    "\n",
    "agent = Agent(model, action_range=(\n",
    "    torch.tensor([-.3, -1.]),\n",
    "    torch.tensor([ 1.,  1.])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    # \"steps\": 10000,  # number of steps we want in one PPO step\n",
    "    \"episodes\": 1,  # number of episodes to collect\n",
    "\n",
    "    # Tensorboard settings\n",
    "    \"tensorboard_name\": \"fixed_speed\",  # str, set explicitly\n",
    "\n",
    "    # PPO\n",
    "    \"ppo_config\": {\n",
    "        # GD settings\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"optimizer_kwargs\": {\n",
    "            \"lr\": 1e-4,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-7,\n",
    "            \"weight_decay\": 0,\n",
    "            \"amsgrad\": False\n",
    "        },\n",
    "        \"gamma\": 0.95,  # Discount factor\n",
    "\n",
    "        # PPO settings\n",
    "        \"ppo_steps\": 10,  # How many max. gradient updates in one iterations\n",
    "        \"eps\": 0.1,  # PPO clip parameter\n",
    "        \"target_kl\": 0.01,  # KL divergence limit\n",
    "        \"value_loss_coeff\": 0.1,\n",
    "        \"entropy_coeff\": 0.1,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "\n",
    "        # Backpropagation settings\n",
    "        \"use_gpu\": False,\n",
    "    }\n",
    "}\n",
    "\n",
    "trainer = PPOCrowdTrainer(agent, env, trainer_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [02:36<3:17:35, 12.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training, logged in /Users/redtachyon/tb_logs/fixed_speed_2020-11-18_18-46-30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-1b26bbed6313>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/CrowdAI/training/trainers.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, num_iterations, save_path, disable_tqdm, **collect_kwargs)\u001B[0m\n\u001B[1;32m    137\u001B[0m             \u001B[0mtimer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 139\u001B[0;31m             \u001B[0mfull_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollect_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_episodes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    140\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m             \u001B[0mdata_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtimer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/CrowdAI/training/collectors.py\u001B[0m in \u001B[0;36mcollect_data\u001B[0;34m(self, num_steps, num_episodes, deterministic, disable_tqdm, max_steps, reset_memory, include_last, reset_start, finish_episode)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m             \u001B[0;31m# Actual step in the environment\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 212\u001B[0;31m             \u001B[0mnext_obs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    213\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m             \u001B[0;31m# Saving to memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/CrowdAI/training/environments.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m    231\u001B[0m         \u001B[0;31m# The terminal step handling has been removed as episodes are only reset from here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 233\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munity\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    234\u001B[0m         \u001B[0mobs_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhas_decision\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_step_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    235\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/site-packages/mlagents_envs/timers.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    303\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    304\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mhierarchical_timer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__qualname__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 305\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    307\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/site-packages/mlagents_envs/environment.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    318\u001B[0m         \u001B[0mstep_input\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_generate_step_input\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_env_actions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    319\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mhierarchical_timer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"communicator.exchange\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 320\u001B[0;31m             \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_communicator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexchange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep_input\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    321\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0moutputs\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    322\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mUnityCommunicatorStoppedException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Communicator has exited.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/site-packages/mlagents_envs/rpc_communicator.py\u001B[0m in \u001B[0;36mexchange\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0mmessage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munity_input\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCopyFrom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munity_to_external\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparent_conn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 118\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll_for_timeout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    119\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munity_to_external\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparent_conn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mheader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m200\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/site-packages/mlagents_envs/rpc_communicator.py\u001B[0m in \u001B[0;36mpoll_for_timeout\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     93\u001B[0m         \u001B[0mlaunched\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m         \"\"\"\n\u001B[0;32m---> 95\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munity_to_external\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparent_conn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout_wait\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     96\u001B[0m             raise UnityTimeOutException(\n\u001B[1;32m     97\u001B[0m                 \u001B[0;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/multiprocessing/connection.py\u001B[0m in \u001B[0;36mpoll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_readable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__enter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/multiprocessing/connection.py\u001B[0m in \u001B[0;36m_poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    423\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 424\u001B[0;31m         \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    425\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/multiprocessing/connection.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 931\u001B[0;31m                 \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mselector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    932\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    933\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfileobj\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevents\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/selectors.py\u001B[0m in \u001B[0;36mselect\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m         \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    414\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 415\u001B[0;31m             \u001B[0mfd_event_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_selector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    416\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mInterruptedError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    417\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:37<00:00, 13.41it/s]\n"
     ]
    }
   ],
   "source": [
    "env.engine_channel.set_configuration_parameters(time_scale=1, width=1000, height=1000, quality_level=0)#, target_frame_rate=600)\n",
    "\n",
    "# import time\n",
    "# time.sleep(2)\n",
    "\n",
    "env.reset()\n",
    "batch = trainer.collector.collect_data(num_episodes=1, disable_tqdm=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnityEnvironmentException\u001B[0m                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-dc5e5f445c52>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/CrowdAI/training/environments.py\u001B[0m in \u001B[0;36mclose\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    258\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 259\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munity\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    260\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mrender\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'human'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/site-packages/mlagents_envs/environment.py\u001B[0m in \u001B[0;36mclose\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    401\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_close\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    402\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 403\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mUnityEnvironmentException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"No Unity environment is loaded.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    404\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    405\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_close\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mUnityEnvironmentException\u001B[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = trainer.collector.collect_data(num_episodes=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "batch = concat_crowd_batch(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "logprobs, values, entropies = agent.evaluate_actions(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2000])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 433/1000 [00:19<00:26, 21.69it/s]\n"
     ]
    },
    {
     "ename": "UnityCommunicatorStoppedException",
     "evalue": "Communicator has exited.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnityCommunicatorStoppedException\u001B[0m         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-53840ef10d3b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mbatch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollect_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_episodes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdisable_tqdm\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/CrowdAI/training/collectors.py\u001B[0m in \u001B[0;36mcollect_data\u001B[0;34m(self, num_steps, num_episodes, deterministic, disable_tqdm, max_steps, reset_memory, include_last, reset_start, finish_episode)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m             \u001B[0;31m# Actual step in the environment\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 212\u001B[0;31m             \u001B[0mnext_obs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    213\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m             \u001B[0;31m# Saving to memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/CrowdAI/training/environments.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m    231\u001B[0m         \u001B[0;31m# The terminal step handling has been removed as episodes are only reset from here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 233\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munity\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    234\u001B[0m         \u001B[0mobs_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhas_decision\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_step_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    235\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/site-packages/mlagents_envs/timers.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    303\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    304\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mhierarchical_timer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__qualname__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 305\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    307\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/site-packages/mlagents_envs/environment.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    320\u001B[0m             \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_communicator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexchange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep_input\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0moutputs\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 322\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mUnityCommunicatorStoppedException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Communicator has exited.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    323\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_update_behavior_specs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    324\u001B[0m         \u001B[0mrl_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrl_output\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mUnityCommunicatorStoppedException\u001B[0m: Communicator has exited."
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(2)\n",
    "\n",
    "env.reset()\n",
    "batch = trainer.collector.collect_data(num_episodes=2, disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = CrowdPPOptimizer(agent, {\"ppo_steps\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0096, -0.0064, -0.2065,  ..., -0.2276, -0.0514,  0.2679],\n",
       "        [ 0.2730, -0.2026, -0.2138,  ...,  0.1657,  0.0743,  0.0466],\n",
       "        [-0.2094,  0.2142,  0.0722,  ..., -0.1446,  0.1019, -0.2680],\n",
       "        ...,\n",
       "        [-0.0843, -0.0358, -0.1844,  ..., -0.0895, -0.0691, -0.1422],\n",
       "        [ 0.1649, -0.1459, -0.2758,  ...,  0.1108,  0.1207,  0.0413],\n",
       "        [-0.0731, -0.1504,  0.0497,  ..., -0.3060, -0.1942,  0.1115]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model.hidden_layers[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crowd/time_update': 0.05107688903808594,\n",
       " 'crowd/kl_divergence': 0.003407703945413232,\n",
       " 'crowd/ppo_steps_made': 5,\n",
       " 'crowd/policy_loss': -0.0008314575534313917,\n",
       " 'crowd/value_loss': 1.4837126731872559,\n",
       " 'crowd/total_loss': 0.29555290937423706,\n",
       " 'crowd/total_steps': 9000.0,\n",
       " 'crowd/episode_len_mean': 500.0,\n",
       " 'crowd/episode_len_median': 500.0,\n",
       " 'crowd/episode_len_min': 500,\n",
       " 'crowd/episode_len_max': 500,\n",
       " 'crowd/episode_len_std': 0.0,\n",
       " 'crowd/episode_reward_mean': -22.172388076782227,\n",
       " 'crowd/episode_reward_median': -19.99441909790039,\n",
       " 'crowd/episode_reward_min': -46.39445877075195,\n",
       " 'crowd/episode_reward_max': -4.994082450866699,\n",
       " 'crowd/episode_reward_std': 12.951112747192383,\n",
       " 'crowd/episodes_this_iter': 18,\n",
       " 'crowd/mean_entropy': -1.480130910873413}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.train_on_data(batch, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0096, -0.0064, -0.2065,  ..., -0.2276, -0.0514,  0.2679],\n",
       "        [ 0.2730, -0.2026, -0.2138,  ...,  0.1657,  0.0743,  0.0466],\n",
       "        [-0.2094,  0.2142,  0.0722,  ..., -0.1446,  0.1019, -0.2680],\n",
       "        ...,\n",
       "        [-0.0843, -0.0358, -0.1844,  ..., -0.0895, -0.0691, -0.1422],\n",
       "        [ 0.1649, -0.1459, -0.2758,  ...,  0.1108,  0.1207,  0.0413],\n",
       "        [-0.0731, -0.1504,  0.0497,  ..., -0.3060, -0.1942,  0.1115]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.model.hidden_layers[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_batch = transpose_batch(batch)\n",
    "\n",
    "all_data = concat_crowd_batch(t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30398947, 0.42324162, 0.43882394, ..., 0.33990902, 0.30477524,\n",
       "       0.28048235], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['actions'].numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7ffc288c7520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(all_data['actions'].numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnityEnvironmentException\u001B[0m                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-1baceacf4cb1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/Coltra-RL/environments.py\u001B[0m in \u001B[0;36mclose\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munity\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/marl/lib/python3.8/site-packages/mlagents_envs/environment.py\u001B[0m in \u001B[0;36mclose\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    401\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_close\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    402\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 403\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mUnityEnvironmentException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"No Unity environment is loaded.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    404\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    405\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_close\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mUnityEnvironmentException\u001B[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.42it/s]\n"
     ]
    }
   ],
   "source": [
    "obs_dict = env.reset()\n",
    "for _ in trange(100):\n",
    "    action_dict = {key: np.array([1., np.random.rand() - 0.5]) for key in obs_dict}\n",
    "    env.step(action_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlagents_envs.base_env.TerminalSteps at 0x7ff3a838b910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unity.get_steps(\"Person2?team=0\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unity.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Person2?team=0&id=10'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-b2d46ebfd909>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mobs_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Person2?team=0&id=10\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m: 'Person2?team=0&id=10'"
     ]
    }
   ],
   "source": [
    "obs_dict[\"Person2?team=0&id=10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 84)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unity.get_steps(\"Person1?team=0\")[0].obs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec, ter = env.unity.get_steps(\"Person2?team=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 84)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.obs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 84), dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ter.obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 196.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(1000):\n",
    "    action_dict = {key: np.array([1., np.random.rand() - 0.5]) for key in obs_dict if key.startswith(\"Person\")}\n",
    "    env.step(action_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 185.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(100):\n",
    "    action_dict = {key: np.array([0., 0.]) for key in obs_dict if key.startswith(\"Person\")}\n",
    "    env.step(action_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.        ,  0.        ,  0.11249997,  0.        ,\n",
       "        1.        ,  0.        ,  0.11704366,  0.        ,  1.        ,\n",
       "        0.        ,  0.11704365,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "        0.        ,  1.        ,  0.        ,  0.18531974,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.17493977,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  1.        ,  0.        ,  0.18531969,\n",
       "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.30322984,  0.        ,  0.        ,\n",
       "        1.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.30596265,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.        ,  1.        ,  1.        , -0.4125    ,\n",
       "       -0.0375    ,  0.25      ,  0.4125    , -0.0375    ,  1.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._get_step_info(False)[0][\"Person1?team=0&id=1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 112.45it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 107.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(50):\n",
    "    env.unity.set_actions(\"Person1?team=0\", np.repeat([[1, -1]], 9, 0))\n",
    "\n",
    "    env.unity.step()\n",
    "    \n",
    "\n",
    "for _ in trange(50):\n",
    "    env.unity.set_actions(\"Person1?team=0\", np.repeat([[1, 1]], 9, 0))\n",
    "\n",
    "    env.unity.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dict, done_dict = env._get_step_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  1.        ,  0.        ,  0.11338039,\n",
       "        0.        ,  1.        ,  0.        ,  0.11338042,  1.        ,\n",
       "       -0.375     ,  0.        ,  0.25      ,  0.45      ,  0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_dict[\"Person1?team=0&id=0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "[[7 8 9]\n",
      " [4 5 6]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "foo = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(foo)\n",
    "print()\n",
    "print(np.take(foo, [2, 1, 0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Person1?team=0': BehaviorSpec(observation_shapes=[(84,), (6,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=2),\n",
       " 'Person2?team=0': BehaviorSpec(observation_shapes=[(84,), (6,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=2)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(env.behavior_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unity.behavior_specs[\"Person1?team=0\"].action_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec, ter = env.unity.get_steps(\"Person1?team=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35005403, 0.33820367, 0.33820558, 0.35005403, 0.35005593,\n",
       "       0.35005403, 0.35005593, 0.35005593, 0.33820558], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  5,  6,  7, 13, 16, 17], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.agent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1: 2, 3: 4}.get(4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [\n",
    "    np.array([1, 2, 3]),\n",
    "    np.array([[2,3,4]]),\n",
    "    np.array([3,4,5])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-3d5441f5c0e8>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array(foo)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([1, 2, 3]), array([[2, 3, 4]]), array([3, 4, 5])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(20):\n",
    "    env.set_actions(\"Person?team=0\", np.repeat([[1, -1]], 18, 0))\n",
    "\n",
    "    env.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ter.agent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.setdefault('k', []).append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': [3]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs(env: UnityEnvironment):\n",
    "    names = env.behavior_specs.keys()\n",
    "    res = {}\n",
    "    for name in names:\n",
    "        decisions, terminals = env.get_steps(name)\n",
    "        for i in decisions.agent_id:\n",
    "            agent_name = f\"{name}&id={i}\"\n",
    "            obs = decisions.obs\n",
    "            \n",
    "\n",
    "\n",
    "def get_step_data(env: UnityEnvironment, names: Sequence[str]):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1, o2 = env.get_steps(\"Person?team=0\")[0].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 84)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 87)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((o1, o2), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs(env: UnityEnvironment, names: Sequence[str]):\n",
    "    res = {}\n",
    "    for name in names:\n",
    "        decisions, terminals = env.get_steps(name)\n",
    "        res[name] = np.concatenate(env.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(100, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _, extra = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-bc86b5fd60d1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "torch.stack(torch.tensor([1, 3, 3, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [np.array([1, 2, 3]) for _ in range(10)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 MARL",
   "language": "python",
   "name": "marl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}